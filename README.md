## Описание проектов

### 1. **Полный цикл анализа данных + реализация градиентного спуска**
*Регрессия, EDA*

**Задача:** Анализ датасетов Titanic и такси с последующей реализацией линейных моделей и градиентного спуска с нуля.

**Основные пункты:**
- Глубокий EDA датасета Titanic: изучение влияния пола, класса, возраста на выживаемость
- Реализация Ridge regression с градиентным спуском (GD, SGD, Momentum, Adagrad)
- Анализ bias-variance через бутстрап

**Наблюдение из анализа:** Momentum показал наилучшую сходимость (427 итераций vs 1000 у GD)

**Стек:** Python, Pandas, NumPy, Matplotlib, Scikit-learn, Statsmodels

---

### 2. **Реализация Decision Tree, Gradient Boosting и анализ ансамблей**
*Ансамбли, Классификация*

**Задача:** Реализация алгоритмов с нуля и сравнение их с промышленными библиотеками.

**Основные пукнты:**
- Реализация `MyDecisionTreeRegressor` с проверкой через `sklearn.utils.estimator_checks`
- Создание `MyGradientBoostingBinaryClassifier` для логистической потери
- Сравнение с XGBoost, LightGBM, CatBoost (F1: 0.949 vs 0.967-0.980)
- Voting Classifier показал лучший результат (F1=0.625)

**Стек:** Python, Scikit-learn, Optuna, XGBoost, LightGBM, CatBoost

---

### 3. **Logistic Regression vs SVM**
*NLP, Обработка текста*

**Задача:** Бинарная и многоклассовая классификация текстов с сравнением классических ML и нейросетевых подходов.

**Основные пункты:**
- Полный пайплайн обработки текстов: токенизация, лемматизация, векторизация (TF-IDF/BoW)
- Сравнение PCA vs t-SNE для визуализации (выяснилось, что t-SNE лучше разделяет, но теряет информацию)
- Подбор гиперпараметров через Optuna
  
**Наблюдение из анализа:** Logistic Regression победила SVM на текстовых данных (F1=0.828)

**Стек:** Python, NLTK, Scikit-learn, Matplotlib, Optuna

---

### 4. **Кластеризация и снижение размерности данных сенсоров**
*Clustering, Dimensionality Reduction*

**Задача:** Анализ многомерных данных с акселерометров смартфона (UCI HAR dataset).

**Основные пункты:**
- Реализация K-Means с нуля (`MyKMeans`) с визуализацией сходимости
- Сравнение PCA и t-SNE методов снижения размерности
- Анализ DBSCAN с различными параметрами eps и min_samples
  
**Наблюдение из анализа:** t-SNE отлично визуализирует, но сильно теряет информацию для классификации

**Стек:** Python, Scikit-learn, Matplotlib, Seaborn

---

### 5. **NER на русских новостях**
*NLP, Named Entity Recognition, Сравнительный анализ*

**Задача:** Распознавание именованных сущностей (PER, LOC, ORG, EVT, PRO) в русскоязычных новостях о Brexit.

**Основные пункты:**
- Поиск информации в интернете (это было частью задания)
- Создание датасета из BSNLP 2019 (9 документов, 152 сущности)
- Сравнение 4 моделей: Logistic Regression показала лучший результат (F1=0.828)
- Глубокий анализ ошибок: все модели путают PER → LOC (систематическая ошибка)
- 17 профессиональных визуализаций, включая radar charts и матрицы ошибок

**Наблюдение из анализа:** На маленьких данных простые линейные модели (Logistic Regression) побеждают сложные

**Стек:** Python, Pandas, Scikit-learn, NLTK, Matplotlib, Seaborn, Joblib
